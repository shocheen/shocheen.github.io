---
title: "Dolma: an Open Corpus of Three Trillion Tokens for Language Model Pretraining Research"
collection: publications
permalink: /publication/2024-01-01-dolma-an-open-corpus-of-three-trillion-tokens-for-language-model-pretraining-research
excerpt: 'This paper is about Dolma: an Open Corpus of Three Trillion Tokens for Language Model Pretraining Research.'
date: 2024-01-01
venue: '2024 Conference of the Association for Computational Linguistics (ACL 2024). Best Resource Paper Award'
paperurl: 'https://arxiv.org/abs/2402.00159'
citation: '[code] Luca Soldaini, Rodney Kinney, Akshita Bhagia, Dustin Schwenk, David Atkinson, Russell Authur, Ben Bogin, Khyathi Chandu, Jennifer Dumas, Yanai Elazar, Valentin Hofmann, Ananya Harsh Jha, Sachin Kumar, Li Lucy, Xinxi Lyu, Nathan Lambert, Ian Magnusson, Jacob Morrison, Niklas Muennighoff, Aakanksha Naik, Crystal Nam, Matthew E. Peters, Abhilasha Ravichander, Kyle Richardson, Zejiang Shen, Emma Strubell, Nishant Subramani, Oyvind Tafjord, Pete Walsh, Luke Zettlemoyer, Noah A. Smith, Hannaneh Hajishirzi, Iz Beltagy, Dirk Groeneveld, Jesse Dodge, Kyle Lo. (2024). &quot;Dolma: an Open Corpus of Three Trillion Tokens for Language Model Pretraining Research.&quot; <i>2024 Conference of the Association for Computational Linguistics (ACL 2024). Best Resource Paper Award</i>.'
---

<a href='https://arxiv.org/abs/2402.00159'>Download paper here</a>

This paper is about Dolma: an Open Corpus of Three Trillion Tokens for Language Model Pretraining Research.

Recommended citation: [code] Luca Soldaini, Rodney Kinney, Akshita Bhagia, Dustin Schwenk, David Atkinson, Russell Authur, Ben Bogin, Khyathi Chandu, Jennifer Dumas, Yanai Elazar, Valentin Hofmann, Ananya Harsh Jha, Sachin Kumar, Li Lucy, Xinxi Lyu, Nathan Lambert, Ian Magnusson, Jacob Morrison, Niklas Muennighoff, Aakanksha Naik, Crystal Nam, Matthew E. Peters, Abhilasha Ravichander, Kyle Richardson, Zejiang Shen, Emma Strubell, Nishant Subramani, Oyvind Tafjord, Pete Walsh, Luke Zettlemoyer, Noah A. Smith, Hannaneh Hajishirzi, Iz Beltagy, Dirk Groeneveld, Jesse Dodge, Kyle Lo. (2024). "Dolma: an Open Corpus of Three Trillion Tokens for Language Model Pretraining Research." <i>2024 Conference of the Association for Computational Linguistics (ACL 2024). Best Resource Paper Award</i>.